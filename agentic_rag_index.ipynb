{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab4e70c-de31-43c8-8e23-ca7631497883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rspamzn/Documents/DevAx/Trainings/NN/agentic-ai/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!pip install matplotlib\n",
    "\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    load_index_from_storage,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    ServiceContext\n",
    ")\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "import faiss\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.response.notebook_utils import display_source_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d09e7b3f-d9df-48ce-8dbb-458b033fdcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/lgmyv6v166l35bqv9zb52bqc0000gr/T/ipykernel_30247/3070529811.py:6: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=None, embed_model=embed_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"data/thinking_machines.txt\"]).load_data()\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"mxbai-embed-large:latest\"\n",
    ")\n",
    "service_context = ServiceContext.from_defaults(llm=None, embed_model=embed_model)\n",
    "splitter = SemanticSplitterNodeParser(buffer_size=1, breakpoint_percentail_thresholed=95,\n",
    "                                      embed_model=embed_model)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01af2741-12cb-42b0-8ab1-86306f4e37bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  ----  Node ID: a37a542d-341c-4467-8c66-f2a8f1e1b3b1\n",
      "Text: When I was an entrepreneur about a decade ago, I landed on a\n",
      "golden use case (or so I fantasised). It is to apply Natural Language\n",
      "Processing (NLP) to convert english statements into structured facts\n",
      "(Subject-Predicate-Object) that adhere to commonly-agreed Domain\n",
      "Ontologies. For example, “Singapore’s economic inflation is estimated\n",
      "at 4.5%” can...\n",
      "1  ----  Node ID: a62ef461-d24f-4306-a2b9-d0a3fa446a65\n",
      "Text: And the 3rd and the 4th are fundamentally similar in the\n",
      "approach. Therefore we can now reduce the categories into two to move\n",
      "forward — 1/symbol manipulation and; 2/sequence transduction using\n",
      "pattern matching. Now, it is important to understand the limitations\n",
      "of both these approaches to avoid rude shocks. In the first symbol\n",
      "manipulation appr...\n",
      "2  ----  Node ID: c728ca39-9028-4c9d-972f-ff80080fc9e5\n",
      "Text: The semantic link missing in this statement is that one needs to\n",
      "buy tickets to get access to the movies. This is one degree of\n",
      "causality. Humans maintain and process massive chains of causalities\n",
      "in our reasoning. Relating statistical correlation scores of n-grams\n",
      "appearing in sentences using multi-dimensional matrices fails in\n",
      "representing suc...\n",
      "3  ----  Node ID: 37871ead-d804-479d-9cac-44e08b9b54f7\n",
      "Text: Before that, I want to dive into making this article a little\n",
      "more contextual for developers. My current job scope is to augment\n",
      "developer productivity and in that scope, code generation using GenAI\n",
      "is an important weapon in any developers’ armoury. And we developers\n",
      "need to know when and where to apply this technology safely!  Back to\n",
      "the 2 cha...\n",
      "4  ----  Node ID: 16bea74e-d745-4385-8e93-ba81d97521ae\n",
      "Text: You may clone my github repo to execute this yourself. Set your\n",
      "OpenAI api key in OPENAI_API_KEY environment variable.  As expected,\n",
      "the program did not work with all the fixes recommended by the model.\n",
      "The trained weights and biases did not converge with the minimal loss\n",
      "value. Some of the fixes given were just redundant distractions. The\n",
      "model...\n",
      "5  ----  Node ID: 3f369d03-c56c-409f-bc94-b4583df37422\n",
      "Text: The limitations of this will be amplified for the users soon\n",
      "(except in the creative use case scenarios) but the LLMs are\n",
      "nevertheless very useful and a great human achievement.\n",
      "6  ----  Node ID: 5f734368-63a8-49e8-aa6d-5144d16d870a\n",
      "Text: The symbol manipulation approach comes from the deterministic\n",
      "mathematical world view of the 19th century. Unless it evolves to\n",
      "accommodate fuzziness and amasses the critical mass of the knowledge\n",
      "base, it will be inadequate too. But it will never hallucinate. There\n",
      "are also other tough philosophical and ethical chasms to cross for\n",
      "both the appr...\n",
      "7  ----  Node ID: 2ec38729-9d15-4e46-a2d1-da5c860414d2\n",
      "Text: Disclaimer : I could be wrong here and I had been wrong before\n",
      ":)\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(nodes):\n",
    "    print(i, \" ---- \", node) #node.get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc9f461c-1e4d-4fed-830a-978f4103b1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_index = faiss.IndexFlatL2(1024)\n",
    "faiss_index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b935376-07f3-4e06-9f62-484edfc7ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex(\n",
    "    nodes, storage_context=storage_context,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4602e28f-cfd8-43c0-b478-139e18e53da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\n",
    "    \"What is the author's current job scope?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2314930-10c5-437d-a5f3-6b910af9bd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 37871ead-d804-479d-9cac-44e08b9b54f7<br>**Similarity:** 290.5322265625<br>**Text:** Before that, I want to dive into making this article a little more contextual for developers. My current job scope is to augment developer productivity and in that scope, code generation using GenAI is an important weapon in any developers’ armoury. And we developers need to know when and where to apply this technology safely!\n",
       "\n",
       "Back to the 2 challenges of hallucination and lacking causality, the first problem is easy in the development domain. The generated code from the models can be easily fact checked — one just have to execute them. That is not hard. Most boiler plate codes have been working well in my tests. The hallucination flaws start to appear when you prompt for the not-so-common patterns (ex. generate a neural net algorithm for x inputs, y hidden nodes, z outputs using a certain activation function). In general application development, such requirements are rare and therefore, using the models to generate the codes do result in 50%+ productivity. The causality challenge is the worst one. In programming, often the decisions made at one part of the code will have multiple hops of connections to the rest. Imagine a state stored in a data member in an object that needs to be reset before a common algorithm in a method is executed. If the developer misses that (the cause) the program spits out bad results (the effect). If such a code is given to the generative models and asked for recommendations to fix it, they predictably struggle all the time. That is the hypothesis and we need to validate this to declare this as the challenging anti-pattern for applying generative models in programming.\n",
       "\n",
       "To prove the hypothesis, I took the case of coding a neural network itself. There is a poetic beauty in this scenario — to get a neural network (GenAI) to produce or fix another neural network. Self Replicating Machines, Wow ! To keep the problem simple, I coded the 2 hidden node network from a Josh Starmer video (btw, if you want to refresh the ML foundations, Josh has an amazingly intuitive guide).\n",
       "\n",
       "I purposefully avoided using the matrices and dot products so that I can create the problem scenario. This is the faulty code that will not converge after back propagation, despite any epoch size.\n",
       "\n",
       "I have coded a piece of langchain client that will invoke OpenAI APIs to get a recommended fix for this code.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 2ec38729-9d15-4e46-a2d1-da5c860414d2<br>**Similarity:** 294.3992004394531<br>**Text:** Disclaimer : I could be wrong here and I had been wrong before :)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n in response.source_nodes:\n",
    "    display_source_node(n, source_length=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3359ff36-e667-46c5-8807-760a97fbeaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15fab746-cb6f-4fe2-adaa-d1d8432a5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FaissVectorStore.from_persist_path(\"./index/default__vector_store.json\")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=\"./index\"\n",
    ")\n",
    "retrieved_index = load_index_from_storage(storage_context=storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "929b5f7c-b8ed-4ae0-b9a3-62363717398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = retrieved_index.as_retriever()\n",
    "response = retriever.retrieve(\n",
    "    \"What is the author's current job scope?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "694a30b6-1d7a-4b12-9953-f029f6a4ac94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 37871ead-d804-479d-9cac-44e08b9b54f7<br>**Similarity:** 290.5322265625<br>**Text:** Before that, I want to dive into making this article a little more contextual for developers. My current job scope is to augment developer productivity and in that scope, code generation using GenAI is an important weapon in any developers’ armoury. And we developers need to know when and where to apply this technology safely!\n",
       "\n",
       "Back to the 2 challenges of hallucination and lacking causality, the first problem is easy in the development domain. The generated code from the models can be easily fact checked — one just have to execute them. That is not hard. Most boiler plate codes have been working well in my tests. The hallucination flaws start to appear when you prompt for the not-so-common patterns (ex. generate a neural net algorithm for x inputs, y hidden nodes, z outputs using a certain activation function). In general application development, such requirements are rare and therefore, using the models to generate the codes do result in 50%+ productivity. The causality challenge is the worst one. In programming, often the decisions made at one part of the code will have multiple hops of connections to the rest. Imagine a state stored in a data member in an object that needs to be reset before a common algorithm in a method is executed. If the developer misses that (the cause) the program spits out bad results (the effect). If such a code is given to the generative models and asked for recommendations to fix it, they predictably struggle all the time. That is the hypothesis and we need to validate this to declare this as the challenging anti-pattern for applying generative models in programming.\n",
       "\n",
       "To prove the hypothesis, I took the case of coding a neural network itself. There is a poetic beauty in this scenario — to get a neural network (GenAI) to produce or fix another neural network. Self Replicating Machines, Wow ! To keep the problem simple, I coded the 2 hidden node network from a Josh Starmer video (btw, if you want to refresh the ML foundations, Josh has an amazingly intuitive guide).\n",
       "\n",
       "I purposefully avoided using the matrices and dot products so that I can create the problem scenario. This is the faulty code that will not converge after back propagation, despite any epoch size.\n",
       "\n",
       "I have coded a piece of langchain client that will invoke OpenAI APIs to get a recommended fix for this code.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 2ec38729-9d15-4e46-a2d1-da5c860414d2<br>**Similarity:** 294.3992004394531<br>**Text:** Disclaimer : I could be wrong here and I had been wrong before :)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n in response:\n",
    "    display_source_node(n, source_length=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb081c-5065-4f2e-afa5-3b1de4269b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "agentic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
